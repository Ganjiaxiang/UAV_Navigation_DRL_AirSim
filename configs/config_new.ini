[options]
; env: SimpleAvoid, NH_center, NH_tree, City
env_name = NH_center
; dynamics: SimpleFixedwing, SimpleMultirotor, Multirotor
dynamic_name = SimpleMultirotor
navigation_3d = True
reward_type = reward_with_action
; algorithm: TD3, PPO, SAC
algo = PPO
total_timesteps = 500000
; policy: CNN_FC, CNN_GAP, CNN_GAP_BN, No_CNN, CNN_MobileNet
policy_name = No_CNN
cnn_feature_num = 25

keyboard_debug = False
generate_q_map = False
q_map_save_steps = 5000
use_wandb = True

[environment]
crash_distance = 2
accept_radius = 2
max_depth_meters = 20

screen_height = 80
screen_width = 100

[multirotor]
dt = 0.1
acc_xy_max = 2.0
v_xy_max = 10.0
v_xy_min = 0.0
v_z_max = 2.0 
yaw_rate_max_deg = 50.0


[fixedwing]
dt = 0.1

[TD3]
gamma = 0.99
learning_rate = 1e-3
learning_starts = 2000
buffer_size = 50000
batch_size = 128
train_freq = 1
gradient_steps = 1
action_noise_sigma = 0.3

[PPO]
learning_rate = 1e-3

[SAC]
learning_rate = 1e-3
learning_starts = 2000
buffer_size = 50000
batch_size = 128
action_noise_sigma = 0.3
train_freq = 1
gradient_steps = 1
