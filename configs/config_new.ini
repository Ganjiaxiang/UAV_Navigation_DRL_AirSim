[options]
; env: SimpleAvoid, NH_center, NH_tree, City, City_400, Tree_200
env_name = Forest
; dynamics: SimpleFixedwing, SimpleMultirotor, Multirotor
dynamic_name = SimpleFixedwing
navigation_3d = False
reward_type = reward_old
; algorithm: TD3, PPO, SAC
algo = SAC
total_timesteps = 200000
; policy: CNN_FC, CNN_GAP, CNN_GAP_BN, No_CNN, CNN_MobileNet, lgmd_split
policy_name = lgmd_split
cnn_feature_num = 25

keyboard_debug = False
generate_q_map = False
q_map_save_steps = 5000
use_wandb = True

;depth, lgmd
perception = lgmd
state_feature_num = 1

[lgmd]
is_split = True
split_row_num = 1
split_col_num = 5
lgmd_perception = lgmd
filter_alpha = 0.7

[environment]
max_depth_meters = 50
screen_height = 80
screen_width = 100

[multirotor]
dt = 0.1
acc_xy_max = 2.0
v_xy_max = 5.0
v_xy_min = 0.5
v_z_max = 2.0 
yaw_rate_max_deg = 50.0

crash_distance = 2
accept_radius = 2


[fixedwing]
dt = 0.1
v_xy_max = 15.0
v_xy_min = 5.0
v_z_max = 5.0 
roll_max_deg = 40.0
roll_rate_max_deg = 60.0
pitch_max_deg = 20.0

crash_distance = 3
accept_radius = 3

pitch_flap_hz = 8
pitch_flap_deg = 3

[TD3]
gamma = 0.99
learning_rate = 1e-3
learning_starts = 2000
buffer_size = 50000
batch_size = 128
train_freq = 1
gradient_steps = 1
action_noise_sigma = 0.3

[PPO]
learning_rate = 1e-3

[SAC]
learning_rate = 1e-2
learning_starts = 1000
buffer_size = 50000
batch_size = 512
action_noise_sigma = 0.1
train_freq = 100
gradient_steps = 100
