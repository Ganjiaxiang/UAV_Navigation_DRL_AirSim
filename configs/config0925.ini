[config]
; navigation in 3d or 2d 
navigation_3d = True
reward_decompose = False
keyboard_debug = False
;if in debug mode, there will be some info printed 
debug_mode = False
;vel or acc control
control_mode = vel
plot_traj = False

[environment]
env_name_gym = airsim-multirotor-v0
env_name_train = forest
max_episode_steps = 400

[goal]
goal_distance = 100
takeoff_hight = 7
goal_angle_noise_degree = 180
goal_accept_radius = 3

work_space_xy_padding = 15   
work_space_z_max = 15
work_space_z_min = 0

[uav_model]
acc_lim_x = 4.0
acc_lim_z = 2.0
acc_lim_yaw_deg = 60.0

max_vel_x = 4.0
min_vel_x = 0.0
max_vel_z = 1.0
max_vel_yaw_deg = 60.0

control_time_interval = 0.2
low_pass_filter_alpha = 0.3

max_vertical_difference = 5
distance_to_obstacles_accept = 1
distance_to_obstacles_punishment = 4

image_form = depth
image_height = 80
image_width = 100
fov_horizontal_degrees = 85
fov_vertical_degrees = 58

[reward]
reward_coeff_obstacle_distance = 0.05
reward_coeff_action_cost = 0.1
reward_coeff_position_cost_up = 0.2
reward_coeff_position_cost_down = 0.2
reward_coeff_position_cost_yaw = 0.1

reward_discount_position_z = 0.7
reward_discount_position_yaw = 0.5
reward_discount_action = 0.3

reward_step_punishment = 0.05
reward_reach = 0
reward_crash = 0

[TD3]
action_noise_sigma = 0.1
eval_freq = 2000
n_eval_episodes = 10
total_timesteps = 300000
gamma=0.99
learning_rate=1e-3
buffer_size=50000
learning_starts=1000
train_freq=200
gradient_steps=200
batch_size=128
